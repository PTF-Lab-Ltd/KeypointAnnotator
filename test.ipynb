{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470b9c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def process_dataset(dataset_path):\n",
    "    \"\"\"Process all images in dataset and save homographies\"\"\"\n",
    "    # Get all images in dataset\n",
    "    images = sorted(glob.glob(f'{dataset_path}/*/*/*.jpg'))\n",
    "    \n",
    "\n",
    "    \n",
    "    for image_path in images:\n",
    "        # Get corresponding annotation path\n",
    "        if 'soccer_worldcup_2014' in image_path:\n",
    "            gt_homo = np.loadtxt(image_path.replace('.jpg', '.homographyMatrix'))\n",
    "        else:\n",
    "            anno_path = image_path.replace(\"Dataset\", \"Annotations\")\n",
    "            # if not os.path.exists(anno_path):\n",
    "            #     print(f\"Skipping {image_path} - no annotation found\")\n",
    "            #     continue\n",
    "                \n",
    "            if 'IMG' in anno_path:\n",
    "                gt_homo = np.load(anno_path.replace('.jpg', '_homography.npy'))\n",
    "            else:\n",
    "                gt_homo = np.load(anno_path.replace('.jpg', '.npy'))\n",
    "\n",
    "        # Create output directory\n",
    "        out_path = image_path.replace(\"Dataset\", \"processed_homographies\")\n",
    "        os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "        \n",
    "        # Save homography\n",
    "        out_file = out_path.replace('.jpg', '.txt')\n",
    "        np.savetxt(out_file, gt_homo)\n",
    "        print(f\"Processed {image_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b013c024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "import utils\n",
    "\n",
    "# Load dense template\n",
    "template_dense = 1 - utils.gen_template_dense_features()\n",
    "\n",
    "def process_dataset(dataset_path):\n",
    "    \"\"\"Process all images in dataset and save homographies\"\"\"\n",
    "    # Get all images in dataset\n",
    "    images = sorted(glob.glob(f'{dataset_path}/*/*/*.jpg'))\n",
    "    \n",
    "    for image_path in images:\n",
    "        # Get corresponding annotation path\n",
    "        if 'soccer_worldcup_2014' in image_path:\n",
    "            gt_homo = np.loadtxt(image_path.replace('.jpg', '.homographyMatrix'))\n",
    "        else:\n",
    "            anno_path = image_path.replace(\"Dataset\", \"Annotations\")\n",
    "            # if not os.path.exists(anno_path):\n",
    "            #     print(f\"Skipping {image_path} - no annotation found\")\n",
    "            #     continue\n",
    "                \n",
    "            if 'IMG' in anno_path:\n",
    "                gt_homo = np.load(anno_path.replace('.jpg', '_homography.npy'))\n",
    "            else:\n",
    "                gt_homo = np.load(anno_path.replace('.jpg', '.npy'))\n",
    "\n",
    "        # Read image\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.resize(image, (1280, 720))\n",
    "        \n",
    "        # Apply homography to dense template\n",
    "        S = np.eye(3)\n",
    "        S[0, 0] = image.shape[1] / 1280\n",
    "        S[1, 1] = image.shape[0] / 720\n",
    "        inv_homo = S @ np.linalg.inv(gt_homo)\n",
    "        \n",
    "        warped_dense = cv2.warpPerspective(template_dense, inv_homo,\n",
    "                                         (image.shape[1], image.shape[0]),\n",
    "                                         cv2.INTER_LINEAR,\n",
    "                                         borderMode=cv2.BORDER_CONSTANT, \n",
    "                                         borderValue=(0)) * 255\n",
    "        \n",
    "        # Process dense visualization\n",
    "        warped_dense[warped_dense < 240] = 0\n",
    "        warped_dense = cv2.cvtColor(warped_dense, cv2.COLOR_GRAY2BGR).astype(np.uint8)\n",
    "        warped_dense[:, :, [0, 2]] = 0  # Keep only green channel\n",
    "        \n",
    "        # Blend with original image\n",
    "        dense_alpha = 0.3\n",
    "        visualization = cv2.addWeighted(image, 1 - dense_alpha, warped_dense, dense_alpha, 0)\n",
    "\n",
    "        # Create output directories\n",
    "        homo_out_path = image_path.replace(\"Dataset\", \"processed_homographies\")\n",
    "        vis_out_path = image_path.replace(\"Dataset\", \"processed_visualizations\") \n",
    "        os.makedirs(os.path.dirname(homo_out_path), exist_ok=True)\n",
    "        os.makedirs(os.path.dirname(vis_out_path), exist_ok=True)\n",
    "        \n",
    "        # Save homography and visualization\n",
    "        homo_out_file = homo_out_path.replace('.jpg', '.txt')\n",
    "        vis_out_file = vis_out_path.replace('.jpg', '_dense.jpg')\n",
    "        np.savetxt(homo_out_file, gt_homo)\n",
    "        cv2.imwrite(vis_out_file, visualization)\n",
    "        \n",
    "        print(f\"Processed {image_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0afb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "import utils\n",
    "\n",
    "# Load template grid points instead of dense template\n",
    "template_grid = utils.gen_template_grid(uniform=False, increase=False)\n",
    "\n",
    "def process_dataset(dataset_path):\n",
    "    \"\"\"Process all images in dataset and save homographies\"\"\"\n",
    "    # Get all images in dataset\n",
    "    images = sorted(glob.glob(f'{dataset_path}/*/*/*.jpg'))\n",
    "    \n",
    "    for image_path in images:\n",
    "        # Get corresponding annotation path\n",
    "        if 'soccer_worldcup_2014' in image_path:\n",
    "            gt_homo = np.loadtxt(image_path.replace('.jpg', '.homographyMatrix'))\n",
    "        else:\n",
    "            anno_path = image_path.replace(\"Dataset\", \"Annotations\")\n",
    "            # if not os.path.exists(anno_path):\n",
    "            #     print(f\"Skipping {image_path} - no annotation found\")\n",
    "            #     continue\n",
    "                \n",
    "            if 'IMG' in anno_path:\n",
    "                gt_homo = np.load(anno_path.replace('.jpg', '_homography.npy'))\n",
    "            else:\n",
    "                gt_homo = np.load(anno_path.replace('.jpg', '.npy'))\n",
    "\n",
    "        # Read image\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.resize(image, (1280, 720))\n",
    "        \n",
    "        # Apply homography to template grid points\n",
    "        S = np.eye(3)\n",
    "        S[0, 0] = image.shape[1] / 1280\n",
    "        S[1, 1] = image.shape[0] / 720\n",
    "        inv_homo = S @ np.linalg.inv(gt_homo)\n",
    "        \n",
    "        # Transform grid points\n",
    "        warped_points = cv2.perspectiveTransform(template_grid[:, :2].reshape(-1, 1, 2), inv_homo).squeeze()\n",
    "        \n",
    "        # Create visualization\n",
    "        visualization = image.copy()\n",
    "        \n",
    "        # Draw lines connecting the grid points\n",
    "        # Vertical lines\n",
    "        for x in np.unique(template_grid[:, 0]):\n",
    "            points = warped_points[template_grid[:, 0] == x]\n",
    "            for i in range(len(points) - 1):\n",
    "                pt1 = tuple(map(int, points[i]))\n",
    "                pt2 = tuple(map(int, points[i + 1]))\n",
    "                cv2.line(visualization, pt1, pt2, (0, 255, 0), 2)\n",
    "                \n",
    "        # Horizontal lines\n",
    "        for y in np.unique(template_grid[:, 1]):\n",
    "            points = warped_points[template_grid[:, 1] == y]\n",
    "            for i in range(len(points) - 1):\n",
    "                pt1 = tuple(map(int, points[i]))\n",
    "                pt2 = tuple(map(int, points[i + 1]))\n",
    "                cv2.line(visualization, pt1, pt2, (0, 255, 0), 2)\n",
    "\n",
    "        # Create output directories\n",
    "        homo_out_path = image_path.replace(\"Dataset\", \"processed_homographies\")\n",
    "        vis_out_path = image_path.replace(\"Dataset\", \"processed_visualizations\") \n",
    "        os.makedirs(os.path.dirname(homo_out_path), exist_ok=True)\n",
    "        os.makedirs(os.path.dirname(vis_out_path), exist_ok=True)\n",
    "        \n",
    "        # Save homography and visualization\n",
    "        # Parse the image filename and extract the number\n",
    "        filename = os.path.basename(image_path)\n",
    "        file_number = re.search(r'\\d+', filename)\n",
    "        if file_number:\n",
    "            file_number = file_number.group().zfill(4)  # Add leading zeros to make it 4 digits\n",
    "        else:\n",
    "            file_number = \"0000\"  # Default if no number is found\n",
    "\n",
    "        # Update output filenames with the formatted number\n",
    "        homo_out_file = homo_out_path.replace('.jpg', f'_{file_number}.txt')\n",
    "        vis_out_file = os.path.join(os.path.dirname(vis_out_path), f'{file_number}_lines.jpg')\n",
    "        np.savetxt(homo_out_file, gt_homo)\n",
    "        cv2.imwrite(vis_out_file, visualization)\n",
    "        \n",
    "        print(f\"Processed {image_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b328973",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/home/ptf/Apps/KeypointAnnotator/dataset/consolidated/Dataset\"\n",
    "process_dataset(dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ef8ad7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1dcf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "def natural_sort_key(s):\n",
    "    \"\"\"\n",
    "    Sort strings containing numbers in natural order.\n",
    "    Example: ['1.jpg', '2.jpg', '10.jpg'] instead of ['1.jpg', '10.jpg', '2.jpg']\n",
    "    \"\"\"\n",
    "    return [int(text) if text.isdigit() else text.lower()\n",
    "            for text in re.split('([0-9]+)', str(s))]\n",
    "\n",
    "\n",
    "def create_videos_from_visualizations(vis_root_path, output_dir, fps=30):\n",
    "    \"\"\"\n",
    "    Create videos from visualization images in subdirectories\n",
    "    \n",
    "    Args:\n",
    "        vis_root_path: Root path containing visualization subdirectories\n",
    "        output_dir: Directory to save output videos\n",
    "        fps: Frames per second for output videos\n",
    "    \"\"\"\n",
    "    # Create output directory\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(\"ololo\")\n",
    "    # Get all subdirectories containing visualizations\n",
    "    subdirs = [d for d in Path(vis_root_path).glob('*/*') if d.is_dir()]\n",
    "    print(subdirs)\n",
    "    for subdir in subdirs:\n",
    "        print(subdir)\n",
    "        # Get all line visualization images in current subdir\n",
    "        images = sorted(glob.glob(str(subdir / '*_lines.jpg')), key=natural_sort_key)\n",
    "\n",
    "        # Check if there are any images        \n",
    "        if not images:\n",
    "            print(f\"No visualization images found in {subdir}\")\n",
    "            continue\n",
    "            \n",
    "        # Create output video filename\n",
    "        video_name = f\"{subdir.parent.name}_{subdir.name}.mp4\"\n",
    "        video_path = os.path.join(output_dir, video_name)\n",
    "        \n",
    "        # FFmpeg command to create video\n",
    "        ffmpeg_cmd = [\n",
    "            'ffmpeg',\n",
    "            '-y',  # Overwrite output files\n",
    "            '-framerate', str(fps),\n",
    "            '-i', f\"{subdir}/%*_lines.jpg\",  # Use natural sorting by specifying a pattern\n",
    "            # '-c:v', 'libx264',\n",
    "            # '-pix_fmt', 'yuv420p',\n",
    "            # '-crf', '23',\n",
    "            video_path\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            print(f\"Creating video for {subdir}\")\n",
    "            subprocess.run(ffmpeg_cmd, check=True, capture_output=True)\n",
    "            print(f\"Successfully created {video_path}\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Error creating video for {subdir}\")\n",
    "            print(f\"FFmpeg error: {e.stderr.decode()}\")\n",
    "\n",
    "vis_root = \"/home/ptf/Apps/KeypointAnnotator/dataset/consolidated/processed_visualizations\"\n",
    "output_dir = \"/home/ptf/Apps/KeypointAnnotator/dataset/consolidated/videos\"\n",
    "\n",
    "create_videos_from_visualizations(vis_root, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6734e93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d9106b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "annotator2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
